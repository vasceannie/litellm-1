model_list:
  - model_name: "mxbai-embed-large"
    litellm_params:
      model: ollama/mxbai-embed-large
      api_base: http://192.168.0.243:11434

  # OpenAI models
  - model_name: "gpt-4o"
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "gpt-4o-mini"
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "gpt-o1"
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "gpt-o1-mini"
    litellm_params:
      model: openai/o1-mini
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "gpt-o1-preview"
    litellm_params:
      model: openai/o1-preview
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "text-embedding-3-large"
    litellm_params:
      model: openai/text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
  - model_name: "text-embeddings-3-small"
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic models
  - model_name: "claude-3.5-sonnet"
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: "claude-3.5-haiku"
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: "claude-3-opus"
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY

  # Groq
  - model_name: "llama-3.3-70b-versatile"
    litellm_params:
      model: groq/llama-3.3-70b-versatile
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.3-70b-specdec"
    litellm_params:
      model: groq/llama-3.3-70b-specdec
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.2-1b-preview"
    litellm_params:
      model: groq/llama-3.2-1b-preview
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.2-3b-preview"
    litellm_params:
      model: groq/llama-3.2-3b-preview
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.2-11b-vision-preview"
    litellm_params:
      model: groq/llama-3.2-11b-vision-preview
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.2-90b-vision-preview"
    litellm_params:
      model: groq/llama-3.2-90b-vision-preview
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.1-70b-versatile"
    litellm_params:
      model: groq/llama-3.1-70b-versatile
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.1-70b-specdec"
    litellm_params:
      model: groq/llama-3.1-70b-specdec
      api_key: os.environ/GROQ_API_KEY
  - model_name: "llama-3.1-8b-instant"
    litellm_params:
      model: groq/llama-3.1-8b-instant
      api_key: os.environ/GROQ_API_KEY

  # Gemini
  - model_name: "gemini-2.0-flash"
    litellm_params:
      model: gemini/gemini-2.0-flash-exp
      api_key: os.environ/GEMINI_API_KEY
  - model_name: "gemini-2.0-flash-thinking"
    litellm_params:
      model: gemini/gemini-2.0-flash-thinking-exp-1219
      api_key: os.environ/GEMINI_API_KEY
  - model_name: "gemini-exp-1206"
    litellm_params:
      model: gemini/gemini-exp-1206
      api_key: os.environ/GEMINI_API_KEY
  
  # DeepSeek
  - model_name: "deepseek-coder"
    litellm_params:
      model: deepseek/deepseek-coder
      api_key: os.environ/DEEPSEEK_API_KEY
  - model_name: "deepseek-chat"
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/DEEPSEEK_API_KEY

  # Cohere
  - model_name: "rerank-v3.5"
    litellm_params:
      model: cohere/rerank-v3.5
      api_key: os.environ/COHERE_API_KEY

litellm_settings:
  set_verbose: True
  drop_params: True
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  service_callback: ["prometheus"]
  langfuse_default_tags:
    - cache_hit
    - cache_key
    - proxy_base_url
    - user_api_key_alias
    - user_api_key_user_id
    - user_api_key_user_email
    - user_api_key_team_alias
    - semantic-similarity
  num_retries: 5
  request_timeout: 600
  telemetry: False
  cache: True
  cache_params:
    type: qdrant-semantic
    qdrant_semantic_cache_embedding_model: ollama/mxbai-embed-large
    qdrant_collection_name: litellm_cache
    qdrant_quantization_config: binary
    similarity_threshold: 0.8

router_settings:
  routing_strategy: usage-based-routing-v2
  redis_host: os.environ/REDIS_HOST
  redis_password: os.environ/REDIS_PASSWORD
  redis_port: os.environ/REDIS_PORT
  redis_username: os.environ/REDIS_USER
  enable_pre_call_checks: true
  # model_group_alias: {"my-special-fake-model-alias-name": "fake-openai-endpoint-3"} 

general_settings: 
  master_key: os.environ/MASTER_KEY
  litellm_salt_key: os.environ/LITELLM_SALT_KEY
  store_model_in_db: True
  proxy_budget_rescheduler_min_time: 60
  proxy_budget_rescheduler_max_time: 64
  proxy_batch_write_at: 1
  database_connection_pool_limit: 10
  database_url: os.environ/DATABASE_URL